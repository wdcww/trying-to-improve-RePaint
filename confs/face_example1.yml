# # # Although image_datasets.py, but conf_base.py
data:
  eval: #conf_base.py/ dset
    paper_face_mask:  #conf_base.py/ dsName
      mask_loader: true
      # # The following is consistent with image_datasets.py/ load_data_inpa()
      gt_path: ./data/datasets/mypic
      mask_path: ./data/datasets/mymask
      batch_size: 1
      image_size: 256 # Resized image(your desired)
#      class_cond: false
      deterministic: true # The opposite of shuffle in Dataloader
      random_crop: false # if true,NotImplementedError()
      random_flip: false
      return_dataloader: true
      return_dict: true
      max_len: 1 # # image_dataset.py/ __len__()
      drop_last: false
      offset: 0
      paths: # # # # # # # # # # # # # #
        srs: ./log/inpainted
        lrs: ./log/gt_masked
#        gts: ./log/gt
#        gt_keep_masks: ./log/gt_keep_mask

show_progress: true


# # unet pre-trained
model_path: ./data/pretrained/celeba256_250000.pt
#model_path: ./data/pretrained/256x256_diffusion_uncond.pt


# # # # gaussian_diffusion.py/ get_named_beta_schedule()
diffusion_steps: 1000
noise_schedule: linear

timestep_respacing: '50' # respace.py
schedule_jump_params:
  t_T: 50 # # # # scheduler.py # # # #
  jump_length: 10
  jump_n_sample: 10


# # inpainting # #
inpa_inj_sched_prev: true # # # # unmasked + masked

# # # 2024.11.6 # # #
use_ddim: false # ddim
eta: 0.0 # ddim eta
# # #

# # # # gaussian_diffusion.py/ p_mean_variance()
learn_sigma: true # # # # # # # # relate with model_var_type

# # # # # #
is_ddpm_paper_get_xprev: false # # # 2024.11.30 # # #
predict_xstart: false # # # # # # relate with model_mean_type
# # # # # #


# # 2024.12.7 # #
use_ref_imgs: true
down_N: 32
range_t: 0
# # # # # #






# # # # script_util.py/ create_gaussian_diffusion()
use_kl: false # relate with loss_type
rescale_learned_sigmas: false # relate with loss_type

rescale_timesteps: false # if True,then NotImplementedError. respace.py/class _WrappedModel

clip_denoised: true # gaussian_diffusion.py/process_xstart()

# # # # script_util.py/ model_and_diffusion_defaults()
image_size: 256 # # also test.py/ sample_fn
num_channels: 256
num_res_blocks: 2
num_heads: 4
num_heads_upsample: -1
num_head_channels: 64
attention_resolutions: 32,16,8
channel_mult: ""
dropout: 0.0
#class_cond: false
use_checkpoint: false # unet.py/class ResBlock
use_scale_shift_norm: true
resblock_updown: true
use_fp16: false
use_new_attention_order: false


# # # #
#lr_kernel_n_std: -1
#num_samples: -1
#n_jobs: -1

#classifier_scale: 4.0
#classifier_use_fp16: false
#classifier_width: 128
#classifier_depth: 2
#classifier_attention_resolutions: 32,16,8
#classifier_use_scale_shift_norm: true
#classifier_resblock_updown: true
#classifier_pool: attention

#latex_name: RePaint
#method_name: Repaint
#name: face_example

#print_estimated_vars: true
#inpa_inj_sched_prev_cumnoise: false


