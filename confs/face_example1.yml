# # # Although image_datasets.py, but conf_base.py
data:
  eval: #conf_base.py/ dset
    paper_face_mask:  #conf_base.py/ dsName
      mask_loader: true
      # # The following is consistent with image_datasets.py/ load_data_inpa()
      gt_path: ./data/datasets/some_my_pic/
      mask_path: ./data/datasets/gt_keep_masks/mytry
      batch_size: 1
      image_size: 256 # Resized image(your desired)
#      class_cond: false
      deterministic: true # The opposite of shuffle in Dataloader
      random_crop: false # if true,NotImplementedError()
      random_flip: false
      return_dataloader: true
      return_dict: true
      max_len: 1 # # image_dataset.py/ __len__()
      drop_last: false
      offset: 0
      paths: # # # # # # # # # # # # # #
        srs: ./log1/inpainted
        lrs: ./log1/gt_masked
#        gts: ./log1/gt
#        gt_keep_masks: ./log1/gt_keep_mask



inpa_inj_sched_prev: true # # # # unmasked + masked


# # unet pre-trained
model_path: ./data/pretrained/celeba256_250000.pt


# # # # gaussian_diffusion.py/ get_named_beta_schedule()
diffusion_steps: 2000 #
noise_schedule: linear #

timestep_respacing: 'ddim50' # respace.py
schedule_jump_params:
  t_T: 50 # # # # scheduler.py # # # #
  n_sample: 2 #
  jump_length: 10
  jump_n_sample: 12


use_ddim: false # # # # # # # # # # # # # # #
eta: 0.0 # # # ddim eta # # #
show_progress: true # # tqdm

# # # # gaussian_diffusion.py/ p_mean_variance()
learn_sigma: true # # # # # # # # relate with model_var_type
predict_xstart: false # # # # # # # # relate with model_mean_type



# # # # script_util.py/ create_gaussian_diffusion()
use_kl: false # relate with loss_type
rescale_learned_sigmas: false # relate with loss_type


rescale_timesteps: false # if True,then NotImplementedError. respace.py/class _WrappedModel

clip_denoised: true # gaussian_diffusion.py/process_xstart()


# # # # script_util.py/ model_and_diffusion_defaults()
image_size: 256 # # also test.py/ sample_fn
num_channels: 256
num_res_blocks: 2
num_heads: 4
num_heads_upsample: -1
num_head_channels: 64
attention_resolutions: 32,16,8
channel_mult: ""
dropout: 0.0
#class_cond: false
use_checkpoint: false # unet.py/class ResBlock
use_scale_shift_norm: true
resblock_updown: true
use_fp16: false
use_new_attention_order: false


# # # #
#lr_kernel_n_std: -1
#num_samples: -1
#n_jobs: -1

#classifier_scale: 4.0
#classifier_use_fp16: false
#classifier_width: 128
#classifier_depth: 2
#classifier_attention_resolutions: 32,16,8
#classifier_use_scale_shift_norm: true
#classifier_resblock_updown: true
#classifier_pool: attention

#latex_name: RePaint
#method_name: Repaint
#name: face_example

#print_estimated_vars: true
#inpa_inj_sched_prev_cumnoise: false


